<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Big Oh</title>
</head>
<body>


    <h1>Big Oh</h1>

    <h1>Big-Oh</h1>

<p>When we look at input sizes large enough to make only the order of growth of the running time relevant, we are studying the asymptotic efficiency of algorithms. That is, we are concerned with how the running time of an algorithm increases with the size of the input in the limit, as the size of the input increases without bound. Usually, an algorithm that is asymptotically more efficient will be the best choice for all but very small inputs.</p>

<p>The formal definitions for Big Oh notation are as follows:</p>

<blockquote>
<p><code>O (g(n))</code> <strong>Big-Oh</strong>. Upper bound. Worst case.<br>
<code>Ω (g(n))</code> <strong>Big-Omega</strong>. Lower bound. Best case, and<br>
<code>Θ (g(n))</code> <strong>Big-Theta</strong>. Bounded upper and lower.  </p>
</blockquote>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Constant     f(n) = 1       No dependence on n.
Logarithmic  f(n) = log n   Binary searches.
Linear       f(n) = n       Each elem once. (Max, Min, Avg)
Superlinear  f(n) = n log n Mergesort and Quicksort. Grows slightly faster than linear.
Quadratic    f(n) = n^2     Items in pairs. 
Cubic        f(n) = n^3     Items in trips.
Exponential  f(n) = 2^n     All subsets of n items.
Factorial    f(n) = n!      All permutations of n items
</code></pre></div>
<p><img src="https://hillscottc.github.io/img/big-oh-chart.png" alt="Big Oh Chart"></p>

<h3>Sort Algortitm speeds</h3>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Most of em :  O(   n^2    )
Merge      :  O( n log(n) )
</code></pre></div>
<h3>Search operation complexity, by structure</h3>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Array/List       :  O(   n    )
Trees            :  O( log(n) )
Adj List         :  O(  |V|   )  # num vertices
Adj Matrix       :  O(   1    ) 
Incidece List    :  O(  |E|   )  # num edges
Incidence Matrix :  O(  |E|   )
</code></pre></div>
<h3>Array, hash by ints, hash by strings</h3>

<p>Given strings A, B, and C.</p>

<ul>
<li><p>array</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">str[3] data;  
data = [A, B, C];
</code></pre></div>
<blockquote>
<p>exists = O(n), get<em>by</em>pos = O(1), get<em>by</em>val = O(n)  </p>
</blockquote></li>
<li><p>hash by seq of ints</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hash{int:str} data;
data = {0:A, 1:B, 2:C};
</code></pre></div>
<blockquote>
<p>exists = O(n), get<em>by</em>pos = O(1), get<em>by</em>val = O(n)  </p>
</blockquote></li>
<li><p>hash with strings</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hash{str:str} data;
data = {A:A, B:B, C:C};
</code></pre></div>
<blockquote>
<p>exists = O(1)<br>
get<em>by</em>pos = O(n), if keys are NOT sorted. Otherwise, O(1)<br>
get<em>by</em>val = O(1), because val is the same as key.</p>
</blockquote></li>
</ul>

<p>basic data structures
<img src="https://hillscottc.github.io/img/complexity-ds.png" alt="basic structures complexity img"></p>

<p>heaps
<img src="https://hillscottc.github.io/img/complexity-heaps.png" alt="heap complexity img"></p>

<p>graphs
<img src="https://hillscottc.github.io/img/complexity-graphs.png" alt="graphs complexity img"></p>


</body>
</html>